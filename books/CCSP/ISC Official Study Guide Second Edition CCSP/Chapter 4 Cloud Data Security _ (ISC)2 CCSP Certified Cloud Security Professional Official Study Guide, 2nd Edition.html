<!DOCTYPE html>
<!-- saved from url=(0086)Chapter 4 Cloud Data Security _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#B9002D">
    <meta data-react-helmet="true" property="og:image" content="https://127.0.0.1/covers/urn:orm:book:9781119603375/"><meta data-react-helmet="true" name="twitter:image" content="https://127.0.0.1/covers/urn:orm:book:9781119603375/"><meta data-react-helmet="true" name="twitter:card" content="summary"><meta data-react-helmet="true" name="twitter:creator" content="@OReillyMedia"><meta data-react-helmet="true" name="twitter:site" content="@OReillyMedia"><meta data-react-helmet="true" name="twitter:title" content="O&#39;Reilly Media - Technology and Business Training"><meta data-react-helmet="true" property="twitter:account_id" content="4503599627559754"><meta data-react-helmet="true" property="og:site_name" content="O&#39;Reilly Online Learning"><meta data-react-helmet="true" name="publisher" content="Sybex"><meta data-react-helmet="true" property="og:book:author" itemprop="author" content="Ben Malisow"><meta data-react-helmet="true" property="og:type" content="book"><meta data-react-helmet="true" property="og:book:isbn" itemprop="isbn" content="9781119603375">


        <link rel="preload" href="public/orm.4899f247a06b19f70f6b.css" as="style">
        <link rel="preload" href="public/main.4899f247a06b19f70f6b.css" as="style">
        <link rel="preload" href="https://127.0.0.1/fonts/GuardianText/GuardianTextSans-Medium-Web.woff2" as="font" type="font/woff2" crossorigin="&quot;anonymous&quot;">
        <link rel="preload" href="https://127.0.0.1/fonts/GuardianText/GuardianTextSans-Regular-Web.woff2" as="font" type="font/woff2" crossorigin="&quot;anonymous&quot;">


    <link rel="shortcut icon" href="https://127.0.0.1/favicon.ico">

      <title>Chapter 4 Cloud Data Security | (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition</title>


        <link rel="stylesheet" href="public/orm.4899f247a06b19f70f6b.css">
        <link rel="stylesheet" href="public/main.4899f247a06b19f70f6b.css">




        <script src="public/orm.4899f247a06b19f70f6b.js.download" defer=""></script>

      <script src="public/main.4899f247a06b19f70f6b.js.download" defer=""></script>




  <meta itemprop="isPartOf" content="/library/view/isc-2-ccsp-certified/9781119603375/" data-react-helmet="true"><meta property="og:url" itemprop="url" content="Chapter 4 Cloud Data Security _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html" data-react-helmet="true"><script data-react-helmet="true">
        var gtmInitialDimensions = {"product":{"title":"(ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition","type":"book","identifier":"9781119603375","topic":"CCSP (Certified Cloud Security Professional)"},"content":{"identifier":"9781119603375-/Chapter 4 Cloud Data Security _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html","publisher":"Sybex","free":"no","subdirectory":"none","subTopic":"none","parentTopic":"none","formatType":"book-chapter","author":"Ben Malisow","releaseDate":"2019-12-24","title":"Chapter 4 Cloud Data Security"}};
        window.dataLayer = window.dataLayer || [];
        var dataLayer = window.dataLayer;
        dataLayer.push(gtmInitialDimensions);
      </script><meta name="search-title" content="Chapter 4 Cloud Data Security" data-react-helmet="true"><meta property="og:title" content="Chapter 4 Cloud Data Security" data-react-helmet="true"><meta itemprop="name" content="Chapter 4 Cloud Data Security" data-react-helmet="true"><meta property="og:description" itemprop="description" content="

Chapter 4
Cloud Data Security


 THE OBJECTIVE OF THIS CHAPTER IS TO ACQUAINT THE READER WITH THE FOLLOWING CONCEPTS:

Domain 1: Cloud Concepts, Architecture, and Design

1.3...." data-react-helmet="true"><meta name="twitter:description" content="

Chapter 4
Cloud Data Security


 THE OBJECTIVE OF THIS CHAPTER IS TO ACQUAINT THE READER WITH THE FOLLOWING CONCEPTS:

Domain 1: Cloud Concepts, Architecture, and Design

1.3...." data-react-helmet="true"></head>
  <body>

    <div id="root"><div class="orm-ff-Shell-shell__wrapper"><a href="Chapter 4 Cloud Data Security _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html#main" class="orm-ff-Shell-skipLink">Skip to content</a><div class="orm-ff-Shell-content__wrapper"><div class="orm-ff-Shell-search orm-ff-Shell-search__wrapper orm-ff-Shell-collapsedSearch"><div class="orm-ff-SearchBarView-searchBarContainer orm-ff-SearchBarView-searchBarWithNewInput"><form role="search" class="orm-ff-SearchBarView-root"><div class="orm-ff-SearchBarView-searchContainer"><div class="orm-Input-root orm-ff-SearchBarView-searchInput  orm-Input-large orm-Input-withIcon"><label for="input-09sh73wvp1zl" class="orm-Input-inputLabel"><span class="orm-Icon-root orm-Input-iconRoot " aria-hidden="true" data-testid="icon" style="height: 1.5rem;"><span class="orm-Icon-icon orm-Input-icon  orm-icon-search " aria-hidden="true" style="font-size: 1.5rem; width: 1.5rem; height: 1.5rem;"></span><span class="orm-Icon-title">search</span></span><input aria-invalid="false" autocomplete="off" class="orm-Input-input orm-ff-SearchBarView-newInput " id="input-09sh73wvp1zl" name="value" placeholder="Search for books, videos, live events, and more" type="search" value=""><span class="orm-Input-labelTxt">Search</span></label></div></div></form></div><div class="orm-ff-Shell-userProfileSection orm-ff-UserProfileWidget-userProfileWrapper"><button aria-expanded="false" aria-label="Your profile" class="orm-Button-root orm-ff-UserProfileWidget-disclosureButton "><span class="orm-Button-btnContentWrap"><span class="orm-Icon-root" data-testid="icon" style="height: 2rem;"><span class="orm-Icon-icon orm-icon-person " aria-hidden="true" style="font-size: 2rem; width: 2rem; height: 2rem;"></span><span class="orm-Icon-title">person</span></span> <span class="orm-Icon-root" data-testid="icon" style="height: 1rem;"><span class="orm-Icon-icon orm-icon-chevron-down " aria-hidden="true" style="font-size: 1rem; width: 1rem; height: 1rem;"></span><span class="orm-Icon-title">chevron down</span></span></span></button><div></div></div></div><div class="orm-ff-Shell-content white--6tN8i ucvMode-white  orm-ff-Shell-authContent orm-ff-Shell-collapsedContent" data-scroll-top=""><main role="main" class="orm-ff-Shell-main orm-ff-Shell-authMain orm-ff-Shell-collapsedMain" id="main" tabindex="-1"><section class="contentContainer--2mK5p white--hhcbS ucvMode-white"><div class="navContainer--2_xPC"><nav class="statusBar--2xaib white--khrWc" data-testid="statusBar"><section class="status--1uP5q"><div class="prevContainer--30LmH"><a class="orm-Link-root" href="Chapter 3 Data Classification _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html"><span class="caret--nhhCZ prev--ARW--"></span> <span class="title--1b0fU">Chapter 3 Data Classification</span></a></div><div data-datadog-id="ucv-nav-title" class="currentTitle--1dL5i">Chapter 4 Cloud Data Security</div><div class="nextContainer--2OsHF"><a class="orm-Link-root" href="Chapter 5 Security in the Cloud _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html"><span class="title--1b0fU">Chapter 5 Security in the Cloud</span> <span class="caret--nhhCZ next--2QWlj"></span></a></div></section></nav></div><article class="contentSection--3h7uJ"><section class="contentViewer--1W37P"><div class="annotatable--2YgjA"><div id="book-content"><div class="readerContainer--2F4Ft white--13FSs" style="font-size: 1em; max-width: 70ch;"><div id="sbo-rt-content"><section epub:type="chapter" role="doc-chapter">
<header>
<h1><span epub:type="pagebreak" role="doc-pagebreak" title="71" id="Page_71"></span><a id="start"></a><span class="chapterNumber">Chapter 4</span>
<br><span class="chapterTitle">Cloud Data Security</span></h1>
</header>
<section id="c04-sec-0001">
<p><b>THE OBJECTIVE OF THIS CHAPTER IS TO ACQUAINT THE READER WITH THE FOLLOWING CONCEPTS:</b></p>
<ul id="c04-list-0001">
<li><b>Domain 1: Cloud Concepts, Architecture, and Design</b>
<ul id="c04-list-0002">
<li>1.3. Understand Security Concepts Relevant to Cloud Computing
<ul id="c04-list-0003">
<li>1.3.1. Cryptography and Key Management</li>
</ul></li>
<li>1.4. Understand Design Principles of Secure Cloud Computing
<ul id="c04-list-0004">
<li>1.4.1. Cloud Secure Data Lifecycle</li>
</ul></li>
</ul></li>
<li><b>Domain 2: Cloud Data Security</b>
<ul id="c04-list-0005">
<li>2.1. Describe Cloud Data Concepts
<ul id="c04-list-0006">
<li>2.1.1. Cloud Data Lifecycle Phases</li>
</ul></li>
<li>2.2. Design and Implement Cloud Data Storage Architectures
<ul id="c04-list-0007">
<li>2.2.1. Storage Types</li>
<li>2.2.2. Threats to Storage Types</li>
</ul></li>
<li>2.3. Design and Apply Data Security Technologies and Strategies
<ul id="c04-list-0008">
<li>2.3.1. Encryption and Key Management</li>
<li>2.3.2. Hashing</li>
<li>2.3.3. Masking</li>
<li>2.3.4. Tokenization</li>
<li>2.3.5. Data Loss Prevention (DLP)</li>
<li>2.3.6. Data Obfuscation</li>
<li>2.3.7. Data De-identification</li>
</ul></li>
<li><span epub:type="pagebreak" role="doc-pagebreak" title="72" id="Page_72"></span>2.8. Design and Implement Auditability, Traceability, and Accountability of Data Events
<ul id="c04-list-0009">
<li>2.8.1. Definition of Event Sources and Requirement of Identity Attribution</li>
<li>2.8.2. Logging, Storage, and Analysis of Data Events</li>
</ul></li>
</ul></li>
<li><b>Domain 3: Cloud Platform and Infrastructure Security</b>
<ul id="c04-list-0010">
<li>3.1. Comprehend Cloud Infrastructure Components
<ul id="c04-list-0011">
<li>3.1.5. Storage</li>
</ul></li>
</ul></li>
<li><b>Domain 5: Cloud Security Operations</b>
<ul id="c04-list-0012">
<li>5.4. Implement Operational Controls and Standards
<ul>
<li>5.4.5. Incident Management</li>
<li>5.4.6. Problem Management</li>
</ul></li>
<li>5.7. Manage Security Operations
<ul id="c04-list-0014">
<li>5.7.3. Log Capture and Analysis</li>
</ul></li>
</ul></li></ul>
<p><span epub:type="pagebreak" role="doc-pagebreak" title="73" id="Page_73"></span><img src="public/clogo.jpg" alt="" width="150" height="150"> While cloud technology might be fairly new, the data security fundamentals remain the same: the CIA triad, regulatory constraints, layered defense, and so forth. In this chapter, we will examine the particular security challenges and techniques necessary for making a cloud format both useful and trustworthy.</p></section>
<section id="c04-sec-0002">
<h2><a id="usec0002"></a>Cloud Data Lifecycle</h2>
<p>Data in the cloud should be perceived, in the general case, to have the same needs and properties as data in the legacy environment. The data lifecycle still has a purpose; only the implementation particulars will change. <a id="figureanchor4-1" role="doc-backlink" href="Chapter 4 Cloud Data Security _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html#figure4-1">Figure 4.1</a> shows the common stages in the data lifecycle.</p>
<figure>
<img class="center" src="public/c04f001.jpg" alt="The figure shows two concentric circles illustrating different stages of the data lifecycle. Where the innermost circle is divided into six parts and each part represents different symbols. The outermost circle is also divided into six parts, labeled “create,” “store,” “use,” “share,” “achieve” and “destroy” (in clock-wise direction).”" width="600" height="600">
<figcaption>
<p><span class="figureLabel"><a id="figure4-1" role="doc-backlink" href="Chapter 4 Cloud Data Security _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html#figureanchor4-1"><b>Figure 4.1</b></a> Stages of the data lifecycle</span></p>
</figcaption>
</figure>
<p>Data will still be created (Create phase)—both in the cloud itself and by remote users. It will be stored, in both the short term (Store phase) and long term (Archive phase), in the cloud. It will be manipulated and modified (Use phase) in the production environment hosted in the cloud. It will be transmitted to other users and made available for collaboration (Share phase) within the cloud; this is one of the significant benefits offered by cloud <span epub:type="pagebreak" role="doc-pagebreak" title="74" id="Page_74"></span>computing. In addition, we will still have a need to remove data from the production environment and sanitize the media afterward (Destroy phase).</p>
<p>Obviously, the particulars for performing these activities, and doing them in a secure fashion, will evolve to match any new environmental challenges.</p>
<p>In the cloud, each phase of the data lifecycle will require particular protections. Let’s review each of the phases in turn and examine some specific control mechanisms we may want to apply in each.</p><section id="c04-sec-0003">
<h3><a id="usec0003"></a>Create</h3>
<p>Data will most often be created by users accessing the cloud remotely. Depending on the use case, the data might be created locally by users at their remote workstation and then uploaded to the cloud or it might be created in the cloud data center via remote manipulation of the data residing there.</p>
<p><b>Data Created Remotely </b>Data created by the user should be encrypted before uploading to the cloud. We want to protect against obvious vulnerabilities, including man-in-the-middle attacks and insider threat at the cloud data center. The cryptosystem used for this purpose should have a high work factor and be listed on the FIPS 140-2 list of approved crypto solutions. We should also implement good key management practices, which we’ll cover later in this chapter.</p>
<section class="feature3" id="c04-feafxd-0001">
<p><img style="vertical-align: middle;" src="public/note.jpg" alt="Image of Note" width="71" height="44"> Sometimes when dealing with keys and managing them, the term <i>public key infrastructure (PKI)</i> is used. PKI is a framework of programs, procedures, communication protocols, and public key cryptography that enables a diverse group of individuals to communicate securely.</p>
</section>
<p>The connection used to upload the data should also be secure, preferably with an IPsec or TLS (1.2 or higher) VPN solution.</p>
<section class="feature3" id="c04-feafxd-0002">
<p><img style="vertical-align: middle;" src="public/note.jpg" alt="Image of Note" width="71" height="44"> TLS replaces the deprecated SSL standard, but SSL is still utilized in many IT environments, and the practitioner may see both the term <i>SSL</i> and the technology used.</p>
</section>
<p><b>Data Created within the Cloud </b>Likewise, data created within the cloud via remote manipulation should be encrypted upon creation, to obviate unnecessary access or viewing by data center personnel. Again, key management should be performed according to best industry practices, as detailed later in this chapter.</p>
<section class="feature3" id="c04-feafxd-0003">
<p><img style="vertical-align: middle;" src="public/note.jpg" alt="Image of Note" width="71" height="44"> Regardless of where, specifically, the data originates—in the cloud data center via remote access or at the user’s location—the Create phase necessitates all the activities described in <a href="Chapter 3 Data Classification _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html">Chapter 3</a>, “Data Classification”: categorization and classification; labeling, tagging, and marking; assigning metadata; and so forth.</p>
</section>
</section>
<section id="c04-sec-0004">
<h3><span epub:type="pagebreak" role="doc-pagebreak" title="75" id="Page_75"></span><a id="usec0004"></a>Store</h3>
<p>From the perspective of the lifecycle diagram, the Store phase takes place right after the Create phase and before the Use and Share phases. This indicates that Store is usually meant to refer to near-term storage (as opposed to the Archive phase, which is obviously long-term storage).</p>
<p>For our purposes, we’ll consider the activity in the Store phase to occur almost concurrently with the Create phase—that is, Store will happen as data is created. In that respect, the actions that should occur here have already been described: encryption at rest for mitigating exposure to threats within the cloud service provider and encryption in transit for mitigating exposure to threats while being moved to the cloud data center.</p></section>
<section id="c04-sec-0005">
<h3><a id="usec0005"></a>Use</h3>
<p>We will need to utilize the same kinds of mechanisms when performing activity in the Use phase as well. Operations in the cloud environment will necessitate remote access, so those connections will all have to be secured, usually with an encrypted tunnel.</p>
<p>Data security in the Use phase will require considering other operational aspects as well. The platforms with which users connect to the cloud have to also be secured; in a BYOD environment, this will entail a holistic approach, since we can never be sure just what devices the users have. Users must be trained to understand the new risks that go along with cloud computing and how they will be expected to use the technology (such as VPN, IRM, and/or DLP agents assigned to them) in a safe manner. Data owners should also be careful to restrict permissions for modifying and processing their data; users should be limited to those functions that they absolutely require in order to perform their assigned tasks. And, as in many circumstances in both the cloud and legacy environments, logging and audit trails are important when data is being manipulated in any fashion.</p>
<p>On the provider side, secure use requires strong protections in the implementation of virtualization; the provider must ensure that data on a virtualized host can’t be read or detected by other virtual hosts on that same device. Also, as has been stated several times (and will be repeated throughout the book), the provider will have to implement personnel and administrative controls so that data center personnel can’t access any raw customer data.</p></section>
<section id="c04-sec-0006">
<h3><a id="usec0006"></a>Share</h3>
<p>Although global collaboration is a powerful capability afforded by the cloud, it comes with risks. If users can be anywhere on the planet, so can threats.</p>
<p>Many of the same security controls implemented in prior phases will be useful here: encrypted files and communications, IRM solutions, and so forth. We also have to craft sharing restrictions based on jurisdiction; we may need to limit or prevent data being sent to certain locations in accordance with regulatory mandates. These restrictions can take the form of either export controls or import controls, so the security professional must be familiar with both for all regions where the organization’s data might be shared.</p>
<section class="feature3" id="c04-feafxd-0004">
<h4 style="background-color: #E7E7E8;"><span epub:type="pagebreak" role="doc-pagebreak" title="76" id="Page_76"></span><img src="public/real.png" alt="Image of Real World Scenario" width="234" height="36"><br> Export and Import Restrictions</h4>
<p>Here are export restrictions you should be familiar with:</p>
<ul id="c04-list-0015">
<li><b>International Traffic in Arms Regulations, or ITAR (United States):</b> State Department prohibitions on defense-related exports; can include cryptography systems.</li>
<li><b>Export Administration Regulations, or EAR (United States):</b> Department of Commerce prohibitions on dual-use items (technologies that could be used for both commercial and military purposes).</li>
</ul>
<p>And here are import restrictions you should be familiar with:</p>
<ul id="c04-list-0016">
<li><b>Cryptography (Various):</b> Many countries have restrictions on importing cryptosystems or material that has been encrypted. When doing business in or with a nation that has crypto restrictions, it is the security professional’s responsibility to know and understand these local mandates.</li>
<li><b>The Wassenaar Arrangement:</b> A group of 41 member countries have agreed to mutually inform each other about conventional military shipments to nonmember countries. Not a treaty, and therefore not legally binding, but may require your organization to notify your government in order to stay in compliance.</li>
</ul>
</section>
<p>Cloud customers should also consider implementing some form of egress monitoring in the Share phase; this will be discussed in the section “Egress Monitoring (DLP)” later in this chapter.</p></section>
<section id="c04-sec-0007">
<h3><a id="usec0007"></a>Archive</h3>
<p>This is the phase for long-term storage, and we necessarily have to consider this longer timeframe when planning security controls for the data.</p>
<p>Cryptography will be, like most data-related controls, an essential consideration. Key management is of utmost importance, because mismanaged keys can lead to additional exposure or to total loss of the data. If the keys are improperly stored (especially if they are stored alongside the data), there is an increased risk of loss; if keys are stored away from the data but not managed properly and lost, there will be no efficient means to recover the data.</p>
<section class="feature3" id="c04-feafxd-0005">
<p><img style="vertical-align: middle;" src="public/note.jpg" alt="Image of Note" width="71" height="44"> One aspect of cryptography to be aware of is elliptical curve cryptography (ECC). This approach to public key cryptography uses much smaller keys than traditional cryptography to provide the same level of security. ECC uses algebraic elliptical curves that result in much smaller keys that can provide the same level of safety as much larger ones used in traditional key cryptography.</p>
</section>
<p><span epub:type="pagebreak" role="doc-pagebreak" title="77" id="Page_77"></span>The physical security of the data in long-term storage is also important. In choosing a storage location, we need to weigh risks and benefits for these facets of physical security:</p>
<p><b>Location </b>Where is the data being stored? What environmental factors will pose risks in that location (natural disasters, climate, etc.)? What jurisdictional aspects might bear consideration (local and national laws)? How distant is the archive location? Will it be feasible to access the data during contingency operations (for instance, during a natural disaster)? Is it far enough to be safe from events that impact the production environment but close enough for personnel to reach that data during those events?</p>
<p><b>Format </b>Is the data being stored on some physical medium such as tape backup or magnetic storage? Is the media highly portable and in need of additional security controls against theft? Will that medium be affected by environmental factors? How long do we expect to retain this data? Will it be in a format still accessible by production hardware when we need it?</p>
<section class="feature3" id="c04-feafxd-0006">
<p><img style="vertical-align: middle;" src="public/note.jpg" alt="Image of Note" width="71" height="44"> Think of all the archaic media formats used to store data in the past, the cost of those formats, and how complicated it would be to find hardware capable of accessing that data today: Jaz disks, Zip disks, Colorado backup tape systems, and so on. Will today’s format be outmoded soon, and will we have the hardware necessary to pull that data into a future format?</p>
</section>
<p><b>Staff </b>Are personnel at the storage location employed by our organization? If not, does the contractor implement a personnel control suite sufficient for our purposes (background checks, reliance checks, monitoring, and so on)?</p>
<p><b>Procedure </b>How is data recovered when needed? How is it ported to the archive on a regular basis? How often are we doing full backups (and the frequency of incremental or differential backups)?</p>
<p>Archive phase activities in the cloud will largely be driven by whether we are doing backups in the cloud, whether we are using the same cloud provider for backups and our production environment, or whether we are using a different cloud provider for each. We have to consider all the same factors we would use in the traditional environment but then also determine whether we could impose those same decisions in the cloud environment, on the cloud provider, via contractual means. How will this be monitored? How will it be enforced?</p></section>
<section id="c04-sec-0008">
<h3><a id="usec0008"></a>Destroy</h3>
<p>We discussed destruction options for the traditional and cloud environments in <a href="Chapter 3 Data Classification _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html">Chapter 3</a>. As we determined, cryptographic erasure (cryptoshredding) is the only feasible and thorough means currently available for this purpose in the cloud environment.</p></section>
</section>
<section id="c04-sec-0009">
<h2><span epub:type="pagebreak" role="doc-pagebreak" title="78" id="Page_78"></span><a id="usec0009"></a>Cloud Storage Architectures</h2>
<p>There are various ways to store data in the cloud, each with attendant benefits and costs. These ways apply both to larger organizational needs and to personal cloud storage of a single user’s data.</p><section id="c04-sec-0010">
<h3><a id="usec0010"></a>Volume Storage: File-Based Storage and Block Storage</h3>
<p>With volume storage, the customer is allocated a storage space within the cloud; this storage space is represented as an attached drive to the user’s virtual machine. From the customer’s perspective, the virtual drive performs very much in the same manner as would a physical drive attached to a tangible device; actual locations and memory addresses are transparent to the user.</p>
<p>Volume storage architecture can take different forms; there is a great deal of discussion among cloud professionals about what type of volume might be preferable: file storage or block storage.</p>
<p><b>File Storage (also File-Level Storage or File-Based Storage) </b>The data is stored and displayed just as with a file structure in the traditional environment, as files and folders, with all the same hierarchical and naming functions. File storage architectures have become popular with big data analytical tools and processes.</p>
<p><b>Block Storage </b>Whereas file storage has a hierarchy of folders and files, block storage is a blank volume that the customer or user can put anything into. Block storage might allow more flexibility and higher performance, but it requires a greater amount of administration and might entail installation of an OS or other app to store, sort, and retrieve the data. Block storage might be better suited for a volume and purpose that includes data of multiple types and kinds, such as enterprise backup services.</p>
<p>Storage architecture for volumes can include bit splitting and erasure coding, which is basically a means of implementing data protection solutions in the cloud similar to the way RAID arrays protect traditional storage. Volume storage can be offered in any of the cloud service models but is often associated with infrastructure as a service&nbsp;(IaaS).</p></section>
<section id="c04-sec-0011">
<h3><a id="usec0011"></a>Object-Based Storage</h3>
<p>Object storage is just as it sounds: data is stored as objects, not as files or blocks. Objects include not only the actual production content, but metadata describing the content and object and a unique address identifier for locating that specific object across an entire storage space.</p>
<p>Object storage architectures allow for a significant level of description, including marking, labels, classification, and categorization. This also enhances the opportunity for indexing capabilities, data policy enforcement (such as IRM, described in <a href="Chapter 3 Data Classification _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html">Chapter 3</a>, and DLP, discussed later in this chapter in the section “Egress Monitoring [DLP]”), and centralization of some data management functions.</p>
<p><span epub:type="pagebreak" role="doc-pagebreak" title="79" id="Page_79"></span>Again, any of the cloud service models can include object storage architectures, but object storage is usually associated with IaaS.</p></section>
<section id="c04-sec-0012">
<h3><a id="usec0012"></a>Databases</h3>
<p>Like their traditional counterparts, databases in the cloud provide some sort of structure for stored data. Data will be arranged according to characteristics and elements in the data itself, including a specific trait required to file the data known as the primary key. In the cloud, the database is usually backend storage in the data center, accessed by users utilizing online apps or APIs through a browser.</p>
<p>Databases can be implemented in any cloud service model, but they are most often configured to work with PaaS and SaaS.</p></section>
<section id="c04-sec-0013">
<h3><a id="usec0013"></a>Content Delivery Network (CDN)</h3>
<p>A content delivery network (CDN) is a form of data caching, usually near geophysical locations of high use/demand, for copies of data commonly requested by users. Perhaps the best example of why an organization would want to use a CDN is online multimedia streaming services: instead of dragging data from a data center to users at variable distances across a continent, the streaming service provider can place copies of the most requested media near metropolitan areas where those requests are likely to be made, thus improving bandwidth and delivery quality.</p></section>
</section>
<section id="c04-sec-0014">
<h2><a id="usec0014"></a>Cloud Data Security Foundational Strategies</h2>
<p>Just as certain technologies make cloud computing feasible as a whole, certain technologies and practices make data security possible in the cloud and therefore also make cloud computing pragmatic and sensible.</p><section id="c04-sec-0015">
<h3><a id="usec0015"></a>Encryption</h3>
<p>It should come as no surprise that cloud computing has a massive dependency on encryption; you have probably noticed how many times, and in how many ways, encryption has been mentioned throughout the book so far.</p>
<p>Encryption will be used to protect data at rest, in transit, and in use. Encryption will be used on the remote user endpoint to create the secure communication connection, within the cloud customer’s enterprise environment to protect their own data, and within the data center by the cloud provider to ensure various cloud customers don’t accidentally access each other’s data.</p>
<p><span epub:type="pagebreak" role="doc-pagebreak" title="80" id="Page_80"></span>Realistically, without encryption it would be impossible to use the cloud in any secure fashion.</p>
<p>The book has included some details about encryption implementations already and will continue to do so as we discuss various aspects of cloud computing. In the following sections, we will focus on only two particular topics of encryption in the cloud: key management and an experimental encryption implementation that might create a whole new level of security and trust in the cloud.</p><section id="c04-sec-0016">
<h4><a id="usec0016"></a>Key Management</h4>
<p>As we have noted before, how and where encryption keys are stored can affect the overall risk of the data significantly. Here are some things to remember and consider regarding key management for cloud computing:</p>
<p><b>Level of Protection </b>Encryption keys, which are the mathematical numeric stringcode that allows for encryption and decryption to occur, must be secured at the same level of control, or <i>higher</i>, as the data they protect. The sensitivity of the data dictates this level of protection, according to the organization’s data security policies. We need to remember that the strength of the cryptosystem is only valid if keys are not disclosed (except for public keys, as part of asymmetric encryption).</p>
<section class="feature3" id="c04-feafxd-0007">
<p><img style="vertical-align: middle;" src="public/note.jpg" alt="Image of Note" width="71" height="44"> Sometimes databases use transparent encryption, in which the encryption key for the database is stored in the database itself.</p>
</section>
<section class="feature3" id="c04-feafxd-0008">
<p><img style="vertical-align: middle;" src="public/note.jpg" alt="Image of Note" width="71" height="44"> A hardware security module (HSM) is a device that can safely store and manage encryption keys and is used in servers, data transmission, and log files. If implemented properly, it is far stronger than saving and storing keys in software.</p>
</section>
<p><b>Key Recovery </b>For anyone other than a specific user, accessing that user’s key should be difficult; however, there are situations in which an organization needs to acquire a user’s key without the user’s cooperation. This might be because the user was fired from the organization, or died, or lost their key. You need to have the technology and process for getting that key to access that data. Usually, this entails a procedure that involves multiple people, each with access to only a portion of the key.</p>
<p><b>Key Distribution </b>Issuing keys for a cryptosystem can be difficult and fraught with risk. If the key management process requires a secure connection to initiate the key creation procedure, how do you establish that secure session without a key? Often, passing keys out of band is a preferable, yet cumbersome and expensive, solution. Moreover, keys should never be passed in the clear.</p>
<p><b>Key Revocation </b>In situations where a user should no longer have access to sensitive material, or where a key has been inadvertently/illicitly disclosed, the organization needs a process for suspending the key or that user’s ability to use it.</p>
<p><span epub:type="pagebreak" role="doc-pagebreak" title="81" id="Page_81"></span><b>Key Escrow </b>In many cases, having copies of keys held by a trusted third party in a secure environment is highly desirable; this can aid in many of the other key management efforts listed in this section.</p>
<p><b>Outsourcing Key Management </b>Keys should not be stored with the data they’re protecting, and we shouldn’t make physical access to keys readily available to anyone who doesn’t have authorization and need to know for that data; therefore, in cloud computing, it is preferable to have the keys stored somewhere other than the cloud provider’s data center. One solution is for the cloud customer to retain the keys, but that requires an expensive and complicated set of infrastructure and skilled personnel. This would attenuate some of the benefit (in reduced costs) we get from offloading our enterprise to the cloud provider. Another option is using a cloud access security broker (CASB). CASBs are third-party providers that handle IAM and key management services for cloud customers; the cost of using a CASB should be much lower than trying to maintain keys within the organization, and the CASB will have core competencies most cloud customers won’t.</p>
<section class="feature3" id="c04-feafxd-0009">
<p><img style="vertical-align: middle;" src="public/note.jpg" alt="Image of Note" width="71" height="44"> Whether or not a cloud customer chooses to use a CASB or other means of key management, the preferred solution is <i>not</i> to store the crypto keys with the cloud provider.</p>
</section>
</section>
</section>
<section id="c04-sec-0017">
<h3><a id="usec0017"></a>Masking, Obfuscation, Anonymization, and Tokenization</h3>
<p>For certain uses in the cloud, we may find it necessary to obscure actual data and instead use a representation of that data. The terms <i>masking</i>, <i>obfuscation</i>, <i>anonymization</i>, and <i>tokenization</i> refer to methods to accomplish this.</p>
<p>Here are some examples of reasons you’d want to do this:</p>
<p><b>Test Environments </b>New software should be tested in sandboxed environments before being deployed to the production environment. When this type of testing is performed, actual production data should <i>never</i> be used within the sandbox. However, in order to determine the actual functionality and performance of the system, it will be necessary to use data that closely approximates the same traits and characteristics of the production data.</p>
<p><b>Enforcing Least Privilege </b>We know that the concept of least privilege entails limiting users to permissions and access absolutely necessary to perform their duties. In some cases, that might mean allowing the user access to elements of a data set without revealing its entirety. For instance, a customer service representative might need to access a customer’s account information and be shown a screen with that information, but that data might be an abridged version of the customer’s total account specifics (such as not showing the customer’s full credit card number).</p>
<p><b>Secure Remote Access </b>When a customer logs onto a web service, the customer’s account might have some data abridged in similar fashion to the least privilege example. The screen might display some of the customer’s preferences, but you might not want to display certain elements of the customer’s account data, such as payment or personal information, to avoid risks such as hijacked sessions, stolen credentials, or shoulder surfing.</p>
<p><span epub:type="pagebreak" role="doc-pagebreak" title="82" id="Page_82"></span>So how are these activities performed? These are some techniques that you can use to obscure data for use in the cloud context:</p>
<p><b>Randomization </b>The replacement of the data (or part of the data) with random characters. Usually, and as with most cases of obscuring data, you want to leave the other traits (aside from displaying the actual data) intact: length of the string, character set (whether it was alphabetic or numerical, whether it had special characters, whether there was upper-/lowercase, etc.), and so forth.</p>
<p><b>Hashing </b>Using a one-way cryptographic function to create a digest of the original data. Using a hash algorithm to obscure the data gives you the benefit of ensuring it is unrecoverable, and you can also use it as an integrity check later. However, because hashing converts variable-length messages into fixed-length digests, you lose many of the properties of the original data.</p>
<p><b>Shuffling </b>Using different entries from within the same data set to represent the data. This has the obvious drawback of using actual production data.</p>
<p><b>Masking </b>Hiding the data with useless characters; for example, showing only the last four digits of a Social Security number: XXX-XX-1234. This can be used where the customer service representative or the customer gets authorized access to the account but you want to obscure a portion of the data for additional security.</p>
<p><b>Nulls </b>Deleting the raw data from the display before it is represented, or displaying null sets. Obviously, some of the functionality of the data set will be dramatically reduced with this method.</p>
<p>The term <i>obfuscation</i> refers to the application of any of these techniques in order to make the data less meaningful, detailed, or readable in order to protect the data or the subject of the data. For instance, I can obfuscate data with masking or by anonymizing it, as will be discussed further in this section.</p>
<p>Obscuring can be done in either static or dynamic configurations. With the static technique, a new (representational) data set is created as a copy from the original data, and only the obscured copy is used. In the dynamic method, data is obscured as it is called, as with the examples I described: the customer service agent or the customer is granted authorized access, but the data is obscured as it is fed to them.</p>
<p>We may also want to add another layer of abstraction to the data to attenuate the possibility that sensitive information may be gleaned from otherwise mundane elements. For instance, even if we’re obscuring a person’s name in a given data set, if we allow other information, such as age, location, and employer, it may be possible to determine the name without having direct access to that field.</p>
<p>Removing the telltale nonspecific identifiers is called <i>anonymization</i> or sometimes <i>de-identification</i>. Anonymization can be difficult, because sensitive data must be recognized and marked as sensitive when it is created; if the user inputs the data into open fields (free entry), determining sensitivity might not be simple. Moreover, the mark indicating sensitivity creates metadata that might be valuable to an attacker.</p>
<p>Tokenization is the practice of having two distinct databases: one with the live, actual sensitive data and one with nonrepresentational tokens mapped to each piece of that data. <span epub:type="pagebreak" role="doc-pagebreak" title="83" id="Page_83"></span>In this method, the user or program calling the data is authenticated by the token server, which pulls the appropriate token from the token database, then calls the actual data that maps to that token from the real database of production data, and finally presents it to the user or program. Tokenization adds significant overhead to the process but creates an extra degree of security and may relieve the organization’s requirement or dependence on encryption (for instance, PCI DSS allows tokenization instead of encryption for sensitive cardholder data). For tokenization to function properly, the token server must have strong authentication protocols. To see how this works a little more clearly, review the following steps, also shown in <a id="figureanchor4-2" role="doc-backlink" href="Chapter 4 Cloud Data Security _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html#figure4-2">Figure 4.2</a></p><ol id="c04-list-0017">
<li>A user creates a piece of data.</li>
<li>The data is run through a DLP/discovery tool, as an aid to determine whether the data is sensitive according to the organization’s rules (in this example, the data is PII). If the data is deemed sensitive, the data is pushed to the tokenization database.</li>
<li>The data is tokenized; the raw data is sent to the PII server, while a token representing the data is stored in the tokenization database. The token represents the raw data as a kind of logical address.</li>
<li>Another user requests the data. This user must be stringently authenticated so the systems can determine if the user should be granted access to the data.</li>
<li>If the user authenticates correctly, the request is put to the tokenization database.</li>
<li>The tokenization database looks up the token of the requested data, then presents that token to the PII database. The raw data is not stored in the tokenization database.</li>
<li>The PII database returns the raw data based on the token.</li>
<li>The raw data is delivered to the requesting user.</li>
</ol>
<figure>
<img class="center" src="public/c04f002.jpg" alt="The figure shows the basic tokenization architecture. " width="800" height="522">
<figcaption>
<p><span class="figureLabel"><a id="figure4-2" role="doc-backlink" href="Chapter 4 Cloud Data Security _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html#figureanchor4-2"><b>Figure 4.2</b></a> Basic tokenization architecture</span></p>
</figcaption>
</figure></section>
<section id="c04-sec-0018">
<h3><span epub:type="pagebreak" role="doc-pagebreak" title="84" id="Page_84"></span><a id="usec0018"></a>Security Information and Event Management</h3>
<p>We use monitoring tools to know how well the systems and security controls in our IT environment are functioning, to detect anomalous activity, and to enforce policy. A large part of the monitoring effort comes in the form of logs: recording activity as it happens, sometimes from specialized devices that only conduct monitoring and other times from operational systems themselves (with their integrated logging functions).</p>
<p>To better collect, manage, analyze, and display log data, a set of tools specifically created for that purpose has become popular. These are known by a variety of terms, since there is no accepted standard. Nomenclature includes security information management, security event management, security information and event management, and permutations of these (including acronyms such as SIM, SEM, and SIEM, pronounced in various ways). We will refer to the entire family of tools inclusively as SIEM.</p>
<p>Goals of SIEM implementation include the following:</p>
<p><b>Centralize Collection of Log Data </b>Because logs can be drawn from so many sources (workstations, OSs, servers, network devices, and so on), it can be useful to have a place to aggregate it all for additional processing. If nothing else, this simplifies the activity for the admins and analysts who will be tasked with monitoring the environment. This does create an additional risk; however: having all the log data in one location makes that location an attractive target for attackers, so any SIEM implementation will require additional layers of security controls.</p>
<p><b>Enhanced Analysis Capabilities </b>Log analysis is a mundane, repetitive task that requires a special skillset and experience and is not suited for full-time tasking (an analyst who stares at the same data set and data feeds all day, day after day, will become inured to the activity, whereas an analyst who doesn’t see the data from the environment often enough won’t be as familiar with the baselines and therefore won’t recognize anomalous behavior). One way we can offset some of the problems with log analysis is to automate some of the process. SIEM tools should have this capability, in addition to other functions such as advanced trend detection based on large data sets. One thing to remember, however, is that most automated tools will not recognize a particular set of attacks—the “low and slow” style of persistent threats, which may develop over weeks or months and don’t have dramatic indicators and therefore may be confused with background attack noise and go undetected by automated analysis.</p>
<p><b>Dashboarding </b>Management often doesn’t understand IT functions, and understands even less about IT security. SIEMs often offer some graphical output display that is more intuitive and simple for managers to quickly grasp situations within the environment.</p>
<p><b>Automated Response </b>Some SIEMs include automated alert and response capabilities that can be programmed to suit your policies and environment.</p>
<section class="feature3" id="c04-feafxd-0010">
<p><img style="vertical-align: middle;" src="public/warn.jpg" alt="Image of Warning" width="69" height="40"> Like logging itself, SIEMs are only useful when someone is actually looking at what they produce; simply having the shiny box that performs security functions is nice, but unless the information it provides is being harvested by someone who knows what they’re looking at, the SIEM can be just another bandage in a damaged environment and won’t really offer any benefit to the organization.</p>
</section>
</section>
<section id="c04-sec-0019">
<h3><span epub:type="pagebreak" role="doc-pagebreak" title="85" id="Page_85"></span><a id="usec0019"></a>Egress Monitoring (DLP)</h3>
<p>Another set of popular tools are for the purpose of egress monitoring—that is, examining data as it leaves the production environment. These are often called DLP, which can stand for any combination of the terms <i>data loss</i>, <i>leak prevention</i>, and <i>protection</i>. I’m just going to refer to them universally as DLP.</p>
<p>Like SIEM, DLP solutions generally have several major goals:</p>
<p><b>Additional Security </b>DLP can be used as another control in the layered defense strategy, one last mechanism designed for mitigating the possibility of inadvertent release or malicious disclosure.</p>
<p><b>Policy Enforcement </b>Users can be alerted by the DLP when they are attempting to perform an action that would violate the organization’s policy (either accidentally or intentionally).</p>
<p><b>Enhanced Monitoring </b>The DLP tool can be set to provide one more log stream to the organization’s monitoring suite.</p>
<p><b>Regulatory Compliance </b>Specific types and kinds of data can be identified by the DLP solution, and dissemination of that data can be controlled accordingly, in order to better adhere to regulatory mandates.</p>
<section class="feature3" id="c04-feafxd-0011">
<p><img style="vertical-align: middle;" src="public/note.jpg" alt="Image of Note" width="71" height="44"> DLP solutions can often be linked to IRM tools, allowing extra functionality to the controls on intellectual property.</p>
</section>
<p>DLP tools can function in a variety of ways, but the general concept is that data is identified, activity is monitored, and policies are enforced.</p>
<p>The identification task can be automated, manual, or a combination of both. The tool might search the organization’s entire storage volumes and production environment to match data against known templates; for instance, the DLP might search for numeric strings nine characters in length in order to detect Social Security numbers. The DLP also might use categorization and classification markings, labels, and metadata assigned by the data owner during the Create phase of the data lifecycle. Or the DLP might use keyword searches for particular information known by the organization to be sensitive for its purposes.</p>
<p>The monitoring task can be implemented at the points of network egress (in traditional systems at the DMZ [demilitarized zone], but in the cloud this would be on all public-facing devices) or on all hosts that process data within the production environment. In the latter case, the DLP solution usually includes local agents installed on user workstations/endpoint devices.</p>
<p>The enforcement mechanism can take many forms. The DLP might be set to alert management or security personnel when a user is conducting an activity that violates policy (say, sending an email attachment that contains data the organization has deemed sensitive). If what we’re trying to prevent is more accidental disclosures (as opposed to malicious activity), the DLP might just warn users that the email they’re sending contains sensitive <span epub:type="pagebreak" role="doc-pagebreak" title="86" id="Page_86"></span>data, and confirm that they really intended to send it. Or the DLP might be a bit more draconian and prevent the user from sending the attachment, locking the user out of the account, and notifying management and security. The organization can tailor DLP action to its own needs.</p>
<p>DLP implementation in the cloud comes with related difficulties and costs, though. For one thing, the cloud provider may not allow the cloud customer sufficient access (in terms of both administrative permissions and installation of the requisite systems for implementation) to the data center environment, complicating successful configuration and usage. DLP utilization also incurs significant processing overhead; all that monitoring and functionality comes with a processing cost.</p></section>
</section>
<section id="c04-sec-0020">
<h2><a id="usec0020"></a>Summary</h2>
<p>This chapter addressed the data lifecycle within the cloud environment as well as specific security challenges in each phase. We looked at different data storage architectures that might be implemented in the cloud, and which service model might be best suited for each. We discussed cryptography, including the importance of and difficulties with key management and the possibility of using homomorphic encryption in the future. We discussed why we might want to obscure raw data and only display selected portions during operations, and we talked about various methods for performing this task. We reviewed SIEM solutions, how and why they’re implemented, and some risks associated with their use. Finally, we addressed the topic of egress monitoring, how DLP tools work, and specific problems that might be encountered when trying to deploy DLP solutions in the cloud.</p></section>
<section id="c04-sec-0021">
<h2><a id="usec0021"></a>Exam Essentials</h2>
<p><b>Understand the risks and security controls associated with each phase of the cloud data lifecycle. </b>Every phase has its own attendant risks, and those risks are usually associated with a particular set or type of security controls.</p>
<p><b>Understand how import/export restrictions affect the field of information security. </b> You should be familiar with the ITAR and the EAR and know what the Wassenaar Arrangement is.</p>
<p><b>Understand the various cloud data storage architectures. </b>Be able to differentiate between file storage, block storage, databases, and CDN.</p>
<p><b>Understand how and why encryption is implemented in the cloud. </b>Know the essential elements of key management; in particular, know that encryption keys are not to be stored alongside the data they were used to encrypt. Know about the emerging technology known as homomorphic encryption and how it might be used in the future to process encrypted data without having to decrypt it first.</p>
<p><span epub:type="pagebreak" role="doc-pagebreak" title="87" id="Page_87"></span><b>Be familiar with the practice of obscuring data. </b>Know the different techniques of data masking, hiding, anonymization, and tokenization.</p>
<p><b>Be familiar with SIEM technology. </b>Understand the purposes of SIEM implementation and the challenges associated with using those solutions.</p>
<p><b>Understand the importance of egress monitoring. </b>Be familiar with the goals of DLP solutions, how they are implemented, and what challenges a cloud customer might face trying to implement DLP within the cloud data center.</p></section>
<section id="c04-sec-0022">
<h2><a id="usec0022"></a>Written Labs</h2>
<ol id="c04-list-0018">
<li>Download and read the ISACA white paper on DLP at <a class="codeLabel" href="http://www.isaca.org/Knowledge-Center/Research/ResearchDeliverables/Pages/Data-Leak-Prevention.aspx">www.isaca.org/ Knowledge-Center/Research/ResearchDeliverables/Pages/ Data-Leak-Prevention.aspx</a>.</li>
<li>In no more than one page, summarize the operational risks listed in Figure 1 of that document.</li>
</ol><section class="exercises">
<h2><span epub:type="pagebreak" role="doc-pagebreak" title="88" id="Page_88"></span><a id="c04-exsec-0001"></a>Review Questions</h2>
<p>You can find the answers to the review questions in <a href="Appendix B Answers to Review Questions _ (ISC)2 CCSP Certified Cloud Security Professional Official Study Guide, 2nd Edition.html">Appendix B</a>.</p><section class="questionSet">
<ol class="questionList">
<li class="essay">
<div class="question">
<p>All of the following are terms used to describe the practice of obscuring original raw data so that only a portion is displayed for operational purposes except ___________________.</p><ol id="c04-list-0019" class="upper-latin">
<li>Tokenization</li>
<li>Data discovery</li>
<li>Obfuscation</li>
<li>Masking</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>The goals of SIEM solution implementation include all of the following except ___________________.</p><ol id="c04-list-0020" class="upper-latin">
<li>Centralization of log streams</li>
<li>Trend analysis</li>
<li>Dashboarding</li>
<li>Performance enhancement</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>The goals of DLP solution implementation include all of the following except ___________________.</p><ol id="c04-list-0021" class="upper-latin">
<li>Policy enforcement</li>
<li>Elasticity</li>
<li>Data discovery</li>
<li>Mitigating loss</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>DLP solutions can aid in deterring loss due to which of the following?</p><ol id="c04-list-0022" class="upper-latin">
<li>Randomization</li>
<li>Inadvertent disclosure</li>
<li>Natural disaster</li>
<li>Device failure</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>DLP solutions can help deter loss because of which of the following?</p><ol id="c04-list-0023" class="upper-latin">
<li>Malicious disclosure</li>
<li>Performance issues</li>
<li>Bad policy</li>
<li>Power failure</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>What is the experimental technology that might lead to the possibility of processing encrypted data without having to decrypt it first?</p><ol id="c04-list-0024" class="upper-latin">
<li>AES</li>
<li>Link encryption</li>
<li><span epub:type="pagebreak" role="doc-pagebreak" title="89" id="Page_89"></span>Homomorphic encryption</li>
<li>One-time pads</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>Proper implementation of DLP solutions for successful function requires which of the following?</p><ol id="c04-list-0025" class="upper-latin">
<li>Accurate data categorization</li>
<li>Physical access limitations</li>
<li>USB connectivity</li>
<li>Physical presence</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>Tokenization requires two distinct ___________________.</p><ol id="c04-list-0026" class="upper-latin">
<li>Authentication factors</li>
<li>Databases</li>
<li>Encryption keys</li>
<li>Personnel</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>Data masking can be used to provide all of the following functionality except ___________________.</p><ol id="c04-list-0027" class="upper-latin">
<li>Secure remote access</li>
<li>Enforcing least privilege</li>
<li>Testing data in sandboxed environments</li>
<li>Authentication of privileged users</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>DLP can be combined with what other security tools to enhance data controls?</p><ol id="c04-list-0028" class="upper-latin">
<li>IRM</li>
<li>SIEM</li>
<li>Kerberos</li>
<li>Hypervisors</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>What are the US State Department controls on technology exports known as?</p><ol id="c04-list-0029" class="upper-latin">
<li>ITAR</li>
<li>EAR</li>
<li>EAL</li>
<li>IRM</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>What are the US Commerce Department controls on technology exports known as?</p><ol id="c04-list-0030" class="upper-latin">
<li>ITAR</li>
<li>EAR</li>
<li>EAL</li>
<li>IRM</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p><span epub:type="pagebreak" role="doc-pagebreak" title="90" id="Page_90"></span>Cryptographic keys for encrypted data stored in the cloud should be ___________________.</p><ol id="c04-list-0031" class="upper-latin">
<li>At least 128 bits long</li>
<li>Not stored with the cloud provider</li>
<li>Split into groups</li>
<li>Generated with dependencies</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>Best practices for key management include all of the following except ___________________.</p><ol id="c04-list-0032" class="upper-latin">
<li>Have key recovery processes</li>
<li>Maintain key security</li>
<li>Pass keys out of band</li>
<li>Ensure multifactor authentication</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>Cryptographic keys should be secured ___________________.</p><ol id="c04-list-0033" class="upper-latin">
<li>To a level at least as high as the data they can decrypt</li>
<li>In vaults</li>
<li>By armed guards</li>
<li>With two-person integrity</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>When crafting plans and policies for data archiving, we should consider all of the following except ___________________.</p><ol id="c04-list-0034" class="upper-latin">
<li>Archive location</li>
<li>The backup process</li>
<li>The format of the data</li>
<li>Immediacy of the technology</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>What is the correct order of the phases of the data lifecycle?</p><ol id="c04-list-0035" class="upper-latin">
<li>Create, Store, Use, Archive, Share, Destroy</li>
<li>Create, Store, Use, Share, Archive, Destroy</li>
<li>Create, Use, Store, Share, Archive, Destroy</li>
<li>Create, Archive, Store, Share, Use, Destroy</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>What are third-party providers of IAM functions for the cloud environment?</p><ol id="c04-list-0036" class="upper-latin">
<li>DLPs</li>
<li>CASBs</li>
<li>SIEMs</li>
<li>AESs</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p><span epub:type="pagebreak" role="doc-pagebreak" title="91" id="Page_91"></span>What is a cloud storage architecture that manages the data in an arrangement of fields according to characteristics of each data element?</p><ol id="c04-list-0037" class="upper-latin">
<li>Object-based storage</li>
<li>File-based storage</li>
<li>Database</li>
<li>CDN</li>
</ol></div>
</li>
<li class="essay">
<div class="question">
<p>What is a cloud storage architecture that manages the data in caches of copied content close to locations of high demand?</p><ol id="c04-list-0038" class="upper-latin">
<li>Object-based storage</li>
<li>File-based storage</li>
<li>Database</li>
<li>CDN</li>
</ol></div>
</li></ol>
</section></section></section>
</section>
</div></div><link rel="stylesheet" href="public/WileyTemplate_v5.5.css" crossorigin="anonymous"></div></div></section><section class="iconMenu--fqXlz" data-testid="sidebarWidget"><div class="icon--1vOa0"><section><button aria-label="Table of Contents" class="widgetBtn--1TMR4" title="Table of Contents"><span class="orm-Icon-root" data-testid="icon" style="height: 1.75rem;"><span class="orm-Icon-icon icon--46dsv  orm-icon-bullet-list " aria-hidden="true" style="font-size: 1.75rem; width: 1.75rem; height: 1.75rem;"></span><span class="orm-Icon-title">table of contents</span></span></button></section></div><div class="icon--1vOa0"><section><button aria-label="Search" class="widgetBtn--2hGLF" title="Search"><span class="orm-Icon-root" data-testid="icon" style="height: 1.75rem;"><span class="orm-Icon-icon icon--1FK59  orm-icon-search " aria-hidden="true" style="font-size: 1.75rem; width: 1.75rem; height: 1.75rem;"></span><span class="orm-Icon-title">search</span></span></button></section></div><div class="icon--1vOa0"><section class="widget--1j29M"><button aria-label="Reader Settings" class="widgetBtn--2pDg1" aria-expanded="false" title="Reader Settings"><span class="orm-Icon-root" data-testid="icon" style="height: 1.75rem;"><span class="orm-Icon-icon icon--X2sbG  orm-icon-settings " aria-hidden="true" style="font-size: 1.75rem; width: 1.75rem; height: 1.75rem;"></span><span class="orm-Icon-title">Settings</span></span></button></section></div><div class="icon--1vOa0"><div tabindex="-1"><div><div class="playlistsDropdown--SMk5s"><div class="dropdownContainer--3VH-P" data-testid="dropdownContainer" tabindex="-1"><button class="playlistsButton--3nCUs button--3qqlT"><span class="orm-Icon-root" data-testid="icon" style="height: 1.5rem;"><span class="orm-Icon-icon playlistIcon--2s7d1  orm-icon-queue " aria-hidden="true" style="font-size: 1.5rem; width: 1.5rem; height: 1.5rem;"></span><span class="orm-Icon-title">queue</span></span></button></div></div></div></div></div></section></article></section></main></div></div></div></div>


</body></html>
